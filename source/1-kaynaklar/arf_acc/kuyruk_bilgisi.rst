.. _arf_acc_kuyruk_bilgisi:

===============
Kuyruk Bilgisi
===============


Her iki kÃ¼mede iÅŸ kuyruÄŸu adlarÄ± ve Ã¶zellikleri aynÄ± ÅŸekilde yapÄ±landÄ±rÄ±lmÄ±ÅŸtÄ±r. 

Zaman zaman bazÄ± kuyruklardaki kaynak miktarÄ± arttÄ±rÄ±labilir ya da azaltÄ±labilir, bazÄ± kuyruklar kullanÄ±mdan kaldÄ±rÄ±labilir. Herhangi bir kuyruÄŸun bilgisine aÅŸaÄŸÄ±daki komutla eriÅŸilebilir: 

.. code-block::

   scontrol show partition=kuyruk_adi 


TÃ¼m kuyruklarÄ±n varsayÄ±lan Ã§alÄ±ÅŸma sÃ¼resi 2 dakikadÄ±r. Betik dosyasÄ±nda zaman bilgisi girilmeyen iÅŸler 2 dakika sonunda otomatik olarak sonlandÄ±rÄ±lmaktadÄ±r. Slurm betik dosyasÄ±nda `#SBATCH -\-time <https://slurm.schedmd.com/sbatch.html>`_ komutu ile hesaplama iÃ§in Ã¶ngÃ¶rÃ¼len zaman bilgisi girilen iÅŸler, belirtilen zaman sonunda otomatik olarak sonlandÄ±rÄ±lmaktadÄ±r. 

Her sunucu ailesinde, sunucu Ã¼zerindeki Ã§ekirdek sayÄ±sÄ±na ve bellek miktarÄ±na baÄŸlÄ± olarak bellek sÄ±nÄ±rlamalarÄ± mevcuttur. EÄŸer betik dosyalarÄ±nda (ya da srun komutunda) herhangi bir bellek deÄŸeri girilmemiÅŸse, ilgili iÅŸ iÃ§in, ``Ã§ekirdek sayÄ±sÄ± x DefMemPerCore`` kadar bellek ayrÄ±lÄ±r. Betik dosyalarÄ±nda (ya da srun komutunda) iÅŸler iÃ§in ``--mem-per-core`` ya da ``--mem`` parametreleri ile daha fazla bellek talebinde bulunulabilir, ancak talep edilen bellek miktarÄ± hiÃ§bir koÅŸulda *maxMemPerCore* degerini geÃ§emez. *MaxMemPerCore* ve *DefMemPerCore* deÄŸerleri her sunucu ailesi iÃ§in farklÄ±dÄ±r. TÃ¼m sunucular iÃ§in bu verilere aÅŸaÄŸÄ±daki tablodan eriÅŸilebilir. 

.. list-table:: Kuyruklar (partitions)
   :widths: 25 25 25 25 25 25 25 25
   :header-rows: 1
   
   * - YÄ±l
     - Adet
     - CPU/GPU
     - Ä°ÅŸlemci Modeli
     - SPECfp_rate_base2006
     - Teorik Gflops
     - Bellek
     - TanÄ±mÄ±
   * - ğŸŸ¢ palamut-cuda
     - palamut
     - 9  
     - 03-00:00:00
     - 16   
     - 7500MB  
     - 16GB
     - Aktif 
   * - ğŸŸ¢ kolyoz-cuda
     - kolyoz
     - 24
     - 03-00:00:00  
     - 16  
     - 16GB 
     - 16GB
     - Aktif



..
  ``mid2`` ve ``long`` kuyruklarÄ±na gÃ¶nderilen iÅŸler sardalya ya da barbun sunucularÄ±nÄ±n herhangi birinde Ã§alÄ±ÅŸmaya baÅŸlayabilirler. Bu kuyruklara gÃ¶nderilecek iÅŸlerin belli bir sunucu ailesi Ã¼zerinde Ã§alÄ±ÅŸmasÄ± isteniyorsa, betik dosyalarÄ±na aÅŸaÄŸÄ±daki tanÄ±mlar yazÄ±lmalÄ±dÄ±r: 

  * barbunlar iÃ§in 

  .. code-block::

   #SBATCH --constraint=barbun 

  * sardalyalar iÃ§in 

  .. code-block::

   #SBATCH --constraint=sardalya 

  .. note::

   --contstraint parametresi yerine -C de kullanÄ±labilir. 

  Ä°ÅŸler Ã¶nceden olduÄŸu gibi Ã¼st kuyruklar yerine doÄŸrudan sardalya, barbun veya diÄŸer kuyruklarÄ±na gÃ¶nderilebilir. 

.. warning::

  *barbun-cuda, akya-cuda*, *palamut-cuda* ve *kolyoz-cuda* kuyruklarÄ±na gÃ¶nderilen iÅŸlerin GPU kullanabilecek ve GPU talep eden iÅŸler olmasÄ± zorunludur.  GPU kÃ¼melerinin kullanÄ±mÄ± ile ilgili dokÃ¼mantasyon :ref:`gpu-kilavuzu` sayfamÄ±zÄ± inceleyebilirsiniz.

..

.. code-block:: 

    sinfo

komutunu kullanarak kuyruklarÄ±n mevcut doluluk durumunu gÃ¶rebilirsiniz. 

*Palamut-cuda*
^^^^^^^^^^^^^^

Her bir sunucuda 128 Ã§ekirdek ve 1TB bellek ayrÄ±ca 8'er adet Nvidia A100 80GB GPU (NVLink) kartÄ± bulunmaktadÄ±r. Kuyrukta iÅŸlerin en fazla Ã§alÄ±ÅŸma sÃ¼resi 3 gÃ¼ndÃ¼r. Sistemin verimli kullanÄ±labilmesi iÃ§in gÃ¶nderilecek iÅŸler en az 16 Ã§ekirdek ve 1 GPU talep etmelidir. AyrÄ±ca sistemlerde scratch olarak kullanÄ±lmak Ã¼zere 12TB NVME disk /localscratch dizinine baÄŸlanmÄ±ÅŸtÄ±r. YÃ¼ksek I/O gerektiren iÅŸlerin /localscratch dizininde Ã§alÄ±ÅŸtÄ±rÄ±lmasÄ± gerekmektedir.

Ä°ÅŸlerde bellek sÄ±nÄ±rlamasÄ± kullanÄ±lmaktadÄ±r. GÃ¶nderilen iÅŸlerin sunucularÄ±n bellek sÄ±nÄ±rlamalarÄ±na uygun olarak gÃ¶nderilmesi gerekmektedir. Bu kuyruk ile ilgili ayrÄ±ntÄ±lÄ± bilgi palamut-ui kullanÄ±cÄ± arayÃ¼zÃ¼ne baÄŸlandÄ±ktan sonra

.. code-block::

   scontrol show partition=palamut-cuda

komutu ile gÃ¶rÃ¼lebilir.


*Kolyoz-cuda*
^^^^^^^^^^^^^^

Her bir sunucuda 64 Ã§ekirdek ve 1TB bellek ayrÄ±ca 4'er adet NVIDIA H100 80GB GPU (NVLink) kartÄ± bulunmaktadÄ±r. Kuyrukta iÅŸlerin en fazla Ã§alÄ±ÅŸma sÃ¼resi 3 gÃ¼ndÃ¼r. Sistemin verimli kullanÄ±labilmesi iÃ§in gÃ¶nderilecek iÅŸler en az 16 Ã§ekirdek ve 1 GPU talep etmelidir. AyrÄ±ca sistemlerde tmp olarak kullanÄ±lmak Ã¼zere 7TB NVME disk / dizinine baÄŸlanmÄ±ÅŸtÄ±r. YÃ¼ksek I/O gerektiren iÅŸlerin / dizininde Ã§alÄ±ÅŸtÄ±rÄ±lmasÄ± gerekmektedir.

Ä°ÅŸlerde bellek sÄ±nÄ±rlamasÄ± kullanÄ±lmaktadÄ±r. GÃ¶nderilen iÅŸlerin sunucularÄ±n bellek sÄ±nÄ±rlamalarÄ±na uygun olarak gÃ¶nderilmesi gerekmektedir. Bu kuyruk ile ilgili ayrÄ±ntÄ±lÄ± bilgi cuda-ui kullanÄ±cÄ± arayÃ¼zÃ¼ne baÄŸlandÄ±ktan sonra

.. code-block::

   scontrol show partition=kolyoz-cuda

komutu ile gÃ¶rÃ¼lebilir.



